medianrentps <- all_medianp %>%
mutate(date=paste("01-",month,"-",year)) %>%
mutate(date=dmy(date)) %>%
select("Suburb","values","date") %>%
mutate(values=as.numeric(values))
medianrentps_plot <- medianrentps %>% ggplot(aes(x=date,y=values,colour=Suburb))+geom_line()
#ggplotly(medianrentps_plot)
#identify regression trees. this will help to identify regions of similar trend
medianrentps_rp <- rpart(values~date,data=medianrentps,control=rpart.control(minsplit=3))
medianrentps_pred <- medianrentps %>% mutate(pred=predict(medianrentps_rp,medianrentps))
medianrentps_rp_plot <- ggplot(medianrentps_pred) + geom_point(aes(x=date,y=values)) + geom_line(aes(x=date,y=pred),colour="orange",size=1.5)
medianrentps_rp_plot
ggplotly(medianrentps_rp_plot)
#tidy data into usable form, keeping suburb, values and date
medianrentps <- all_medianp %>%
mutate(date=paste("01-",month,"-",year)) %>%
mutate(date=dmy(date)) %>%
select("Suburb","values","date") %>%
mutate(values=as.numeric(values))
medianrentps_plot <- medianrentps %>% ggplot(aes(x=date,y=values,colour=Suburb))+geom_line()
#ggplotly(medianrentps_plot)
#identify regression trees. this will help to identify regions of similar trend
medianrentps_rp <- rpart(values~date,data=medianrentps,control=rpart.control(minsplit=3))
medianrentps_pred <- medianrentps %>% filter(Suburb == "Bayside") %>% mutate(pred=predict(medianrentps_rp,medianrentps))
#identify regression trees. this will help to identify regions of similar trend
medianrentps_rp <- medianrentps %>% filter(Suburb == "Bayside") %>% rpart(values~date,control=rpart.control(minsplit=3))
#ggplotly(medianrentps_plot)
medianrentps <- medianrentps %>% filter(Suburb=="Bayside")
#tidy data into usable form, keeping suburb, values and date
medianrentps <- all_medianp %>%
mutate(date=paste("01-",month,"-",year)) %>%
mutate(date=dmy(date)) %>%
select("Suburb","values","date") %>%
mutate(values=as.numeric(values))
medianrentps_plot <- medianrentps %>% ggplot(aes(x=date,y=values,colour=Suburb))+geom_line()
#ggplotly(medianrentps_plot)
medianrentps <- medianrentps %>% filter(Suburb=="Bayside")
#identify regression trees. this will help to identify regions of similar trend
medianrentps_rp <- rpart(values~date,data=medianrentps,control=rpart.control(minsplit=3))
medianrentps_pred <- medianrentps %>% mutate(pred=predict(medianrentps_rp,medianrentps))
medianrentps_rp_plot <- ggplot(medianrentps_pred) + geom_point(aes(x=date,y=values)) + geom_line(aes(x=date,y=pred),colour="orange",size=1.5)
ggplotly(medianrentps_rp_plot)
#identify regression trees. this will help to identify regions of similar trend
medianrentps_rp <- rpart(values~date,data=medianrentps,control=rpart.control(minsplit=1))
#tidy data into usable form, keeping suburb, values and date
medianrentps <- all_medianp %>%
mutate(date=paste("01-",month,"-",year)) %>%
mutate(date=dmy(date)) %>%
select("Suburb","values","date") %>%
mutate(values=as.numeric(values))
medianrentps_plot <- medianrentps %>% ggplot(aes(x=date,y=values,colour=Suburb))+geom_line()
#ggplotly(medianrentps_plot)
medianrentps <- medianrentps %>% filter(Suburb=="Bayside")
#identify regression trees. this will help to identify regions of similar trend
medianrentps_rp <- rpart(values~date,data=medianrentps,control=rpart.control(maxsplit=3))
medianrentps_pred <- medianrentps %>% mutate(pred=predict(medianrentps_rp,medianrentps))
medianrentps_rp_plot <- ggplot(medianrentps_pred) + geom_point(aes(x=date,y=values)) + geom_line(aes(x=date,y=pred),colour="orange",size=1.5)
ggplotly(medianrentps_rp_plot)
#identify regression trees. this will help to identify regions of similar trend
medianrentps_rp <- rpart(values~date,data=medianrentps,control=rpart.control(minsplit=3))
#tidy data into usable form, keeping suburb, values and date
medianrentps <- all_medianp %>%
mutate(date=paste("01-",month,"-",year)) %>%
mutate(date=dmy(date)) %>%
select("Suburb","values","date") %>%
mutate(values=as.numeric(values))
medianrentps_plot <- medianrentps %>% ggplot(aes(x=date,y=values,colour=Suburb))+geom_line()
#ggplotly(medianrentps_plot)
medianrentps <- medianrentps %>% filter(Suburb=="Bayside")
#identify regression trees. this will help to identify regions of similar trend
medianrentps_rp <- rpart(values~date,data=medianrentps,control=rpart.control(minsplit=3))
medianrentps_pred <- medianrentps %>% mutate(pred=predict(medianrentps_rp,medianrentps))
medianrentps_rp_plot <- ggplot(medianrentps_pred) + geom_point(aes(x=date,y=values)) + geom_line(aes(x=date,y=pred),colour="orange",size=1.5)
ggplotly(medianrentps_rp_plot)
#tidy data into usable form, keeping suburb, values and date
medianrentps <- all_medianp %>%
mutate(date=paste("01-",month,"-",year)) %>%
mutate(date=dmy(date)) %>%
select("Suburb","values","date") %>%
mutate(values=as.numeric(values))
medianrentps_plot <- medianrentps %>% ggplot(aes(x=date,y=values,colour=Suburb))+geom_line()
#ggplotly(medianrentps_plot)
#medianrentps <- medianrentps %>% filter(Suburb=="Bayside")
#identify regression trees. this will help to identify regions of similar trend
medianrentps_rp <- rpart(values~date,data=medianrentps,control=rpart.control(minsplit=3))
medianrentps_pred <- medianrentps %>% mutate(pred=predict(medianrentps_rp,medianrentps))
medianrentps_rp_plot <- ggplot(medianrentps_pred) + geom_point(aes(x=date,y=values)) + geom_line(aes(x=date,y=pred),colour="orange",size=1.5)
ggplotly(medianrentps_rp_plot)
glimpse(medianrentps)
#the types of data given by the ABS regional data is numerous.
unique(abslgadata$`Data Item`)
#the types of data given by the ABS regional data is numerous.
unique(abslgadata$`Data Items`)
#the types of data given by the ABS regional data is numerous.
unique(abslgadata$`Data item`)
#the types of data given by the ABS regional data is numerous.
as_tibble(unique(abslgadata$`Data item`))
#this shows that there are a total of 398 different data items! majority of this data is collected annually, however some of these data items have missing data items
vis_dat(abslgadata)
#this shows that there are a total of 398 different data items! majority of this data is collected annually, however some of these data items have missing data items
vis_dat(abslgadata,warn_large_data=FALSE)
#unique(abslgadata$`Data item`) #Shows unique data items within abslgadata
#unique(abslgadata$Region) #Shows unique LGAs within abslgadata
glimpse(abslgadata)
#this shows that there are a total of 398 different data items! majority of this data is collected annually, however some of these data items have missing data items
abslgadata %>% spread(key=Time,value=Value)
vis_dat(abslgadata_spreadbyyear,warn_large_data=FALSE)
#this shows that there are a total of 398 different data items! majority of this data is collected annually, however some of these data items have missing data items
abslgadata_spreadbyyear <- abslgadata %>% spread(key=Time,value=Value)
vis_dat(abslgadata_spreadbyyear,warn_large_data=FALSE)
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata %>% group_by(`Data item`,Region) %>% summarise(count = count(Time),na.rm=TRUE)
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata %>% group_by(`Data item`,Region) %>% summarise(count = count(Time,na.rm=TRUE))
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata %>% group_by(`Data item`,Region) %>% summarise(count = count(Time)
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% group_by(`Data item`,Region) %>% summarise(count = count(Time))
abslgadata_countyears
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% group_by(`Data item`,Region) %>% summarise(count = count(Time))
abslgadata_countyears
View(abslgadata_countyears)
View(abslgadata_countyears)
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% group_by(`Data item`,Region) %>% summarise(count = count(Time))
abslgadata_countyears
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% group_by(`Data item`,Suburb) %>% summarise(count = count(Time))
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% group_by(`Data item`,Region) %>% summarise(count = count(Time))
abslgadata_countyears
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% group_by(`Data item`,Region) %>% summarise(count = count(Value))
abslgadata_countyears
library(learnr)
knitr::opts_chunk$set(echo = TRUE,
message = FALSE,
warning = FALSE,
collapse = TRUE,
fig.height = 6,
fig.width = 6,
fig.align = "center",
cache = FALSE)
tutorial_html_dependency()
library(tidyverse)
library(plotly)
library(readxl)
library(visdat)
library(foreign)
library(maptools)
library(ggmap)
library(plyr)
library(lubridate)
library(rpart)
library(rpart.plot)
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% group_by(Region) %>% summarise(count = count(Value))
abslgadata_countyears
?summarise
library(learnr)
knitr::opts_chunk$set(echo = TRUE,
message = FALSE,
warning = FALSE,
collapse = TRUE,
fig.height = 6,
fig.width = 6,
fig.align = "center",
cache = FALSE)
tutorial_html_dependency()
library(tidyverse)
library(plotly)
library(readxl)
library(visdat)
library(foreign)
library(maptools)
library(ggmap)
library(plyr)
library(lubridate)
library(rpart)
library(rpart.plot)
all <- read_xlsx("data/Quarterly median rents by local government area - March quarter 2018.xlsx",sheet = 7)
head(all)
all <- all[,-1]
#all <- all %>% rename("Suburb" = "X__2")
colnames(all)[1] <- "Suburb"
vec1 <- seq(2,ncol(all),2)
vec2 <- seq(3,ncol(all),2)
colnames(all)[vec2] <- colnames(all)[vec1]
colnames(all)[vec1] <- paste(colnames(all)[vec2],"_Count",sep='')
colnames(all)[vec2] <- paste(colnames(all)[vec2],"_Median",sep='')
all <- all[-c(1,90),]
all_f <- all %>% gather(variable, values, -Suburb) %>% arrange(Suburb)
all_f <- all_f %>% separate(variable, c("month","year","type"),by="_")
all_medianp <- all_f %>% filter(type == "Median")
all_counts <- all_f %>% filter(type == "Count")
vis_dat(all)
# to retrieve the average lat and lon from the files
LGACouncil <- read_csv("data/fileslocalgovt.csv")
LatLon <- read_csv("data/Australian_Post_Codes_Lat_Lon 2.csv")
LatLon <- LatLon[,c(1,2,3,6,7)]
LatLon <- LatLon %>% filter(state == 'VIC')
LatLon <- LatLon %>% mutate(Postcode = postcode)
LatLon <- LatLon[,c(6,2,4,5)]
LGACouncil <- LGACouncil[,c(1,4,7)]
#match the coordinate with the LGA
LGAjoin <- left_join(LGACouncil,LatLon, by='Postcode')
#LGA_mod <- LGAjoin %>% group_by(Name) %>% mutate(avg_lat = mean(lat),avg_lon = mean(lon))
LGA <- LGAjoin[!duplicated(LGA_mod$LGA),]
abslgadata1 <- read_csv("data/ABS_REGIONAL_LGA2017-enp1.csv")
abslgadata2 <- read_csv("data/ABS_REGIONAL_LGA2017-enp2.csv")
abslgadata <- rbind(abslgadata1,abslgadata2) %>% select(-MEASURE,-REGIONTYPE,-`Geography Level`,-LGA_2017,-FREQUENCY,-Frequency,-TIME,-`Flag Codes`,-Flags)
#unique(abslgadata$`Data item`) #Shows unique data items within abslgadata
#unique(abslgadata$Region) #Shows unique LGAs within abslgadata
glimpse(abslgadata)
#tidy data into usable form, keeping suburb, values and date
medianrentps <- all_medianp %>%
mutate(date=paste("01-",month,"-",year)) %>%
mutate(date=dmy(date)) %>%
select("Suburb","values","date") %>%
mutate(values=as.numeric(values))
medianrentps_plot <- medianrentps %>% ggplot(aes(x=date,y=values,colour=Suburb))+geom_line()
ggplotly(medianrentps_plot)
#medianrentps <- medianrentps %>% filter(Suburb=="Bayside")
#identify regression trees. this will help to identify regions of similar trend
medianrentps_rp <- rpart(values~date,data=medianrentps,control=rpart.control(minsplit=3))
medianrentps_pred <- medianrentps %>% mutate(pred=predict(medianrentps_rp,medianrentps))
medianrentps_rp_plot <- ggplot(medianrentps_pred) + geom_point(aes(x=date,y=values)) + geom_line(aes(x=date,y=pred),colour="orange",size=1.5)
ggplotly(medianrentps_rp_plot)
#applying a regression tree allows us to identify different partitions in the data. there final partition and most relevant (as it is closest to present time) begins in 01-Jun-2011. This is convenient, as the ABS has begun collecting specific regional data on LGAs beginning
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% group_by(Region) %>% summarise(count = count(Value))
abslgadata_countyears
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% group_by(Region) %>% dplyr::summarise(count = count(Value))
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% group_by(`Data item`,Region) %>% dplyr::summarise(count = count(Value))
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% group_by(`Data item`,Region) %>% dplyr::summarise(count = count(Time))
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% group_by(`Data item`,Region) %>% plyr::summarise(count = count(Time))
abslgadata_countyears
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% group_by(`Data item`,Region) %>% dplyr::summarise(count = count(Time))
abslgadata$Time
count(abslgadata$Time)
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% select(-Value) %>% group_by(`Data item`,Region) %>% dplyr::summarise(count = count(Time))
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% select(-"Value"") %>% group_by(`Data item`,Region) %>% dplyr::summarise(count = count(Time))
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% select(-"Value") %>% group_by(`Data item`,Region) %>% dplyr::summarise(count = count(Time))
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% select(-Value) %>% group_by(`Data item`,Region) %>% dplyr::summarise(count = count(Time))
test <- abslgadata %>% select(-Value)
glimpse(test)
count(test$Time)
test %>% group_by(`Data item`,Region) %>% dplyr::summarise(count=count(Time))
test %>% group_by(`Data item`,Region) %>% count(Time) #dplyr::summarise(count=count(Time))
test %>% group_by(`Data item`,Region) %>% count(test, Time) #dplyr::summarise(count=count(Time))
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% select(-Value) %>% group_by(`Data item`,Region,Time) %>% dplyr::summarise(count = count(Time))
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% select(-Value) %>% group_by(`Data item`,Region) %>% dplyr::summarise(count = count(Region))
count(test$`Data item`)
?count
e
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% select(-Value) %>% group_by(`Data item`,Region) %>% dplyr::summarise(count = dplyr::count(Time))
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% group_by(`Data item`,Region) %>% dplyr::summarise(count = dplyr::count(Time))
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% group_by(`Data item`,Region) %>% plyr::summarise(count = dplyr::count(Time))
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% group_by(`Data item`,Region) %>% dplyr::summarise(count = plyr::count(Time))
dplyr::count(test$Time)
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% group_by(`Data item`,Region) #%>% dplyr::summarise(count = dplyr::count(Time))
glimpse(abslgadata_countyears)
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% group_by(`Data item`,Region) %>% count(Time) #%>% dplyr::summarise(count = dplyr::count(Time))
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% group_by(`Data item`,Region) %>% summarise(no_years = sum(!is.na(Time)) #%>% dplyr::summarise(count = dplyr::count(Time))
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% group_by(`Data item`,Region) %>% summarise(no_years = sum(!is.na(Time))) #%>% dplyr::summarise(count = dplyr::count(Time))
#we then remove the data that has less than 6 data points and see what information we're left with. we do not wish to impute the missing values as it may be making the incorrect assumption that the change of all these data items are related to each other per LGA.
abslgadata_countyears <- abslgadata %>% group_by(`Data item`,Region) %>% summarise(no_years = sum(!is.na(Time))) #%>% dplyr::summarise(count = dplyr::count(Time))
glimpse(abslgadata_countyears)
library(learnr)
knitr::opts_chunk$set(echo = TRUE,
message = FALSE,
warning = FALSE,
collapse = TRUE,
fig.height = 6,
fig.width = 6,
fig.align = "center",
cache = FALSE)
tutorial_html_dependency()
library(tidyverse)
library(plotly)
library(readxl)
library(visdat)
library(foreign)
library(maptools)
library(ggmap)
library(plyr)
library(lubridate)
library(rpart)
library(rpart.plot)
library(regex)
library(learnr)
knitr::opts_chunk$set(echo = TRUE,
message = FALSE,
warning = FALSE,
collapse = TRUE,
fig.height = 6,
fig.width = 6,
fig.align = "center",
cache = FALSE)
tutorial_html_dependency()
library(tidyverse)
library(plotly)
library(readxl)
library(visdat)
library(foreign)
library(maptools)
library(ggmap)
library(plyr)
library(lubridate)
library(rpart)
library(rpart.plot)
library(regex)
install.packages("regex")
library(learnr)
knitr::opts_chunk$set(echo = TRUE,
message = FALSE,
warning = FALSE,
collapse = TRUE,
fig.height = 6,
fig.width = 6,
fig.align = "center",
cache = FALSE)
tutorial_html_dependency()
library(tidyverse)
library(plotly)
library(readxl)
library(visdat)
library(foreign)
library(maptools)
library(ggmap)
library(plyr)
library(lubridate)
library(rpart)
library(rpart.plot)
library(regex)
install.packages("regex")
abslgadata1 <- read_csv("data/ABS_REGIONAL_LGA2017-enp1.csv")
abslgadata2 <- read_csv("data/ABS_REGIONAL_LGA2017-enp2.csv")
abslgaviclgas <- read_xlsx("data/abslgaviclgas.xlsx")
abslgadata <- rbind(abslgadata1,abslgadata2)
#we want to remove anything related to age, gender or race as this is another part of the analysis
abslgadata <- abslgadata[!grepl("ERP",abslgadata$MEASURE),] #population data
abslgadata <- abslgadata[!grepl("CENSUS",abslgadata$MEASURE),] #census data
abslgadata <- abslgadata[!grepl("BD",abslgadata$MEASURE),] #birth/death data
#remove unnecessary columns
abslgadata <- abslgadata %>% select(-REGIONTYPE,-`Geography Level`,-LGA_2017,-FREQUENCY,-Frequency,-TIME,-`Flag Codes`,-Flags)
#identify victorian lgas
abslgaviclgas <- abslgaviclgas %>% mutate (VIC_LGAS=sub("(.*)\\s.*","\\1",VIC_LGAS)) %>% mutate (VIC_LGAS=sub("(.*)\\s.*","\\1",VIC_LGAS)) %>% mutate (VIC_LGAS=sub("(.*)\\s.*","\\1",VIC_LGAS))
#filter out all the data points which are not related to victoria
absviclgadata <- filter(abslgadata,Region %in% abslgaviclgas$VIC_LGAS)
as.tibble(unique(absviclgadata$`Data item`)) #Shows unique data items within abslgadata
#this tells us that there are 398 unique data items
as.tibble(unique(absviclgadata$Region)) #Shows unique LGAs within abslgadata
#this tells us that there are 552 unique LGAs
#abslgadata <- abslgadata %>%
glimpse(absviclgadata)
#tidy data into usable form, keeping suburb, values and date
medianrentps <- all_medianp %>%
mutate(date=paste("01-",month,"-",year)) %>%
mutate(date=dmy(date)) %>%
select("Suburb","values","date") %>%
mutate(values=as.numeric(values))
medianrentps_plot <- medianrentps %>% ggplot(aes(x=date,y=values,colour=Suburb))+geom_line()
ggplotly(medianrentps_plot)
#medianrentps <- medianrentps %>% filter(Suburb=="Bayside")
#identify regression trees. this will help to identify regions of similar trend
medianrentps_rp <- rpart(values~date,data=medianrentps,control=rpart.control(minsplit=3))
medianrentps_pred <- medianrentps %>% mutate(pred=predict(medianrentps_rp,medianrentps))
medianrentps_rp_plot <- ggplot(medianrentps_pred) + geom_point(aes(x=date,y=values)) + geom_line(aes(x=date,y=pred),colour="orange",size=1.5)
ggplotly(medianrentps_rp_plot)
#applying a regression tree allows us to identify different partitions in the data. there final partition and most relevant (as it is closest to present time) begins in 01-Jun-2011. This is convenient, as the ABS has begun collecting specific regional data on LGAs beginning
all_medianp_2018 <- all_medianp %>% filter(year == 2018)
all_medianp_2018 <- all_medianp_2018 %>% mutate(LGA = Suburb)
all_medianp_2018 <- all_medianp_2018[,c(6,2,3,4,5)]
LGA <- LGA %>% arrange(LGA)
all_medianp_2018 <- all_medianp_2018 %>% arrange(LGA)
loc_2018 <- right_join(LGA,all_medianp_2018,by='LGA')
vic <- get_map(location=c(lon=144.9460, lat=-37.8150), zoom=9)
all <- read_xlsx("data/Quarterly median rents by local government area - March quarter 2018.xlsx",sheet = 7)
head(all)
all <- all[,-1]
#all <- all %>% rename("Suburb" = "X__2")
colnames(all)[1] <- "Suburb"
vec1 <- seq(2,ncol(all),2)
vec2 <- seq(3,ncol(all),2)
colnames(all)[vec2] <- colnames(all)[vec1]
colnames(all)[vec1] <- paste(colnames(all)[vec2],"_Count",sep='')
colnames(all)[vec2] <- paste(colnames(all)[vec2],"_Median",sep='')
all <- all[-c(1,90),]
all_f <- all %>% gather(variable, values, -Suburb) %>% arrange(Suburb)
all_f <- all_f %>% separate(variable, c("month","year","type"),by="_")
all_medianp <- all_f %>% filter(type == "Median")
all_counts <- all_f %>% filter(type == "Count")
vis_dat(all)
# to retrieve the average lat and lon from the files
LGACouncil <- read_csv("data/fileslocalgovt.csv")
LatLon <- read_csv("data/Australian_Post_Codes_Lat_Lon 2.csv")
LatLon <- LatLon[,c(1,2,3,6,7)]
LatLon <- LatLon %>% filter(state == 'VIC')
LatLon <- LatLon %>% mutate(Postcode = postcode)
LatLon <- LatLon[,c(6,2,4,5)]
LGACouncil <- LGACouncil[,c(1,4,7)]
#match the coordinate with the LGA
LGAjoin <- left_join(LGACouncil,LatLon, by='Postcode')
#LGA_mod <- LGAjoin %>% group_by(Name) %>% mutate(avg_lat = mean(lat),avg_lon = mean(lon))
LGA <- LGAjoin[!duplicated(LGA_mod$LGA),]
LGA <- LGA[,-c(1,4)]
LGA <- LGA[,c(2,1,3,4)]
LGA <- LGA %>% separate(LGA,sep="[(]",c("LGA","Index"))
# remove trailing whitespace
trim.trailing <- function (x) sub("\\s+$", "", x)
LGA$LGA <- trim.trailing(LGA$LGA)
LGA <- LGA[,-2]
all_medianp_2018 <- all_medianp %>% filter(year == 2018)
all_medianp_2018 <- all_medianp_2018 %>% mutate(LGA = Suburb)
all_medianp_2018 <- all_medianp_2018[,c(6,2,3,4,5)]
LGA <- LGA %>% arrange(LGA)
all_medianp_2018 <- all_medianp_2018 %>% arrange(LGA)
loc_2018 <- right_join(LGA,all_medianp_2018,by='LGA')
vic <- get_map(location=c(lon=144.9460, lat=-37.8150), zoom=9)
all_medianp_2018 <- all_medianp %>% filter(year == 2018)
all_medianp_2018 <- all_medianp_2018 %>% mutate(LGA = Suburb)
all_medianp_2018 <- all_medianp_2018[,c(6,2,3,4,5)]
LGA <- LGA %>% arrange(LGA)
all_medianp_2018 <- all_medianp_2018 %>% arrange(LGA)
loc_2018 <- right_join(LGA,all_medianp_2018,by='LGA')
vic <- get_map(location=c(lon=144.9460, lat=-37.8150), zoom=8)
# to retrieve the average lat and lon from the files
LGACouncil <- read_csv("data/fileslocalgovt.csv")
LatLon <- read_csv("data/Australian_Post_Codes_Lat_Lon 2.csv")
LatLon <- LatLon[,c(1,2,3,6,7)]
LatLon <- LatLon %>% filter(state == 'VIC')
LatLon <- LatLon %>% mutate(Postcode = postcode)
LatLon <- LatLon[,c(6,2,4,5)]
LGACouncil <- LGACouncil[,c(1,4,7)]
#match the coordinate with the LGA
LGAjoin <- left_join(LGACouncil,LatLon, by='Postcode')
#LGA_mod <- LGAjoin %>% group_by(Name) %>% mutate(avg_lat = mean(lat),avg_lon = mean(lon))
LGA <- LGAjoin[!duplicated(LGA_mod$LGA),]
LGA <- LGA[,-c(1,4)]
LGA <- LGA[,c(2,1,3,4)]
LGA <- LGA %>% separate(LGA,sep="[(]",c("LGA","Index"))
# remove trailing whitespace
trim.trailing <- function (x) sub("\\s+$", "", x)
LGA$LGA <- trim.trailing(LGA$LGA)
LGA <- LGA[,-2]
all_medianp_2018 <- all_medianp %>% filter(year == 2018)
all_medianp_2018 <- all_medianp_2018 %>% mutate(LGA = Suburb)
all_medianp_2018 <- all_medianp_2018[,c(6,2,3,4,5)]
LGA <- LGA %>% arrange(LGA)
all_medianp_2018 <- all_medianp_2018 %>% arrange(LGA)
loc_2018 <- right_join(LGA,all_medianp_2018,by='LGA')
vic <- get_map(location=c(lon=144.9460, lat=-37.8150), zoom=8)
vic <- get_map(location=c(lon=144.9460, lat=-37.8150), zoom=8)
ggplotly(m)
vic <- get_map(location=c(lon=144.9460, lat=-37.8150), zoom=7)
ggplotly(m)
vic <- get_map(location=c(lon=144.9460, lat=-37.8150), zoom=7)
vic <- get_map(location=c(lon=144.9460, lat=-37.8150), zoom=8)
ggplotly(m)
vic <- get_map(location=c(lon=144.9460, lat=-37.8150), zoom=8)
View(medianrentps)
#look at historical rental price reacted to the Australian economy
gdp <- read_csv("GDP.csv")
#look at historical rental price reacted to the Australian economy
gdp <- read_csv("data/GDP.csv")
View(gdp)
gdp <- gdp %>% filter(LOCATION == "AUS")
gdp <- gdp[,c(1,6,7)]
gdp_plot <- gdp %>% ggplot(aes(x=TIME,y=Value))+geom_line()
ggplotly(medianrentps_plot)
ggplotly(gdp_plot)
m1 <- lm(gdp$Value~gdp$TIME)
resid(m1)
plot(density(resid(m1)))
resid(m1)
View(m1)
gdp_slope <- gdp %>% mutate(rate = Value - lag(Value, default = 0))
View(gdp_slope)
gdp_slope <- gdp %>% mutate(rate = Value - lag(Value, default = 1))
gdp_slope <- gdp %>% mutate(rate = Value - lag(Value, default = 1))
gdp_slope <- gdp %>% mutate(rate = Value - lag(Value, default = 0))
gdp_slope <- gdp %>% mutate(rate = Value - lag(Value, default = Value[1]))
gdp_slope <- gdp %>% mutate(rate = Value - lag(Value, default = Value[1]))
rate_plot <- gdp_slope %>% ggplot(aes(x=TIME,y=rate))+geom_line()
ggploty(rate_plot)
ggplotly(rate_plot)
gdp_slope <- gdp %>% mutate(volume = Value - lag(Value, default = Value[1]))
gdp_slope <- gdp %>% mutate(rate = volume / lag(Value, default = Value[1]))
gdp_slope <- gdp_slope %>% mutate(rate = volume / lag(Value, default = Value[1]))
rate_plot <- gdp_slope %>% ggplot(aes(x=TIME,y=rate))+geom_line()
ggplotly(rate_plot)
